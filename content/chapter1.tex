\chapter{Einleitung} \label{chap:intro}

Im Zentrum des ersten Kapitels stehen die Vorstellung des Themas der Arbeit, der relevanten Konzepte und die Auflistung der zentralen Fragestellungen.

\section{Projekt Natur 4.0}

Der \emph{LOEWE-Schwerpunkt Natur 4.0 Sensing Biodiversity} (abgekürzt: Natur 4.0) ist ein Gemeinschaftsprojekt der federführenden Philipps-Universität Marburg, der Justus-Liebig-Universität Gießen, der Technischen Universität Darmstadt und der Senckenberg Gesellschaft für Naturforschung in Frankfurt. Ziel des Projekts ist die Entwicklung eines Umweltmonitoringsystems zur hoch aufgelösten Beobachtung von naturschutzrelevanten Arten, Lebensräumen und Prozessen durch vernetzte Sensorik und integrative Datenanalyse\footfullcite{LOEWE-Natur4.0}. Das Testgebiet für die Prototypentwicklung von Natur 4.0 ist der Marburger Universitätswald in Caldern.

Einer der Schwerpunkte des Projekts liegt auf \textbf{der visuellen Erkennung von Tierarten}. Die Ergebnisse dieser Aufgabe ermöglichen zusammen mit weiteren zeitlichen und räumlichen Sensordaten die Beantwortung folgender Fragen: Welche Tierarten sind im Testgebiet vorhanden? Wann, wie häufig, wo genau und unter welchen Bedingungen kommen sie vor? Antworten auf diese Fragestellungen erweisen sich als wertvoll: Sie geben nicht nur Auskunft über die biologische Vielfalt und Eigenschaften von Ökosystemen im Testgebiet, sondern auch über die Wechselwirkungen zwischen Tieren, Pflanzen und klimatischen Bedingungen darin. Aus solchen Informationen lassen sich verschiedene Naturschutzstrategien ableiten.

Zur visuellen Erkennung von Tierarten werden im Testgebiet des Projekts Natur 4.0 \emph{Kamerafallen} installiert. Diese sind wärme- oder bewegungsaktivierte Kameras, die in freier Wildbahn platziert werden, um Tierpopulationen sowie ihr Verhalten zu überwachen und untersuchen. Da die manuelle Auswertung der Aufnahmen extrem aufwändig ist, benötigt man ein System zur automatisierten Tierarterkennung auf Bildern. Dieses System wird im Rahmen dieser Arbeit entwickelt.

\section{Objekterkennung} \label{sec:objectdetection}

Bei einem gegebenen Bild gilt die visuelle Erkennung von Tierarten als erfolgreich, wenn alle Tiere in diesem Bild gefunden und richtig kategorisiert werden. Die Aufgabe ist also ein typisches Beispiel für das \emph{Objekterkennungsproblem} im Forschungsfeld \emph{Computer Vision}. Dabei erfolgt die Objekterkennung in zwei Schritten.

\begin{enumerate}
	\item \emph{Objektlokalisierung}: Der erste Schritt bezieht sich auf das Identifizieren der Position eines oder mehrerer Objekte in einem Bild und das Zeichnen einer Bounding Box um ihre Ausdehnung.
	
	\item \emph{Bildklassifizierung}: Bei dem zweiten Schritt handelt es sich um die Aufgabe, einem Bildobjekt ein Label aus einem festen Satz von Kategorien zuzuweisen.
\end{enumerate}

Man verwendet einen \emph{datengetriebenen Ansatz}, um das Objekterkennungsproblem zu behandeln. Die Idee dabei ist, Algorithmen (im Weiteren als \emph{Modelle} bezeichnet) zu entwickeln (\emph{trainieren}), die durch Daten lernen und das erlernte Wissen anwenden können, um relevante Probleme zu lösen. Zur Objekterkennung wird ein Modell mit vielen Bildern jeder einzelnen Objektklasse trainiert. Während des Trainings lernt das Modell visuelle Merkmale, die Objekte von der Umgebung sowie jede Klasse voneinander trennen. Ergebnis der Lernphase ist ein \emph{trainiertes Modell}, das Objekte in neuen Bilddaten erkennen können soll.

%Die Idee dabei ist, dem Computer viele Bilder jeder einzelnen Objektklasse bereitzustellen und dann mit dem Computer Lernalgorithmen zu entwickeln (\emph{trainieren}), die sich diese Bilder ansehen und visuelle Merkmale lernen, die Objekte von ihrer Umgebung und jede Klasse voneinander trennen. 

\subsection{Convolutional Neural Network}

Für die Objekterkennung benutzt man einen bestimmten Typ von Modellen namens \emph{Convolutional Neural Network} (CNN) (mehr dazu im \autoref{sec:cnn}). Ein CNN-Modell besteht allgemein aus Schichten – Teilalgorithmen mit jeweils unterschiedlicher Funktionalität (z.~B. Merkmalextraktion oder Fehlerkorrektur). Unterschiedliche CNN-Modelle verfügen über verschiedene Anordnungen von Schichten (Architekturen), jedoch haben alle CNN-Modelle die gleiche Funktionsweise: In den vorderen Schichten lernen CNNs \emph{Low-Level-Merkmale} zu erkennen und setzen diese anschließend in den nächsten zu \emph{Higher-Level-Merkmalen} zusammen. Beispielweise kann ein CNN-Modell in niedrigeren Schichten lernen, Kanten oder Linien oder auch Kurven aus Pixeln der Eingabebilder zu identifizieren, während es in höheren Schichten komplexere Formen sowie visuelle Merkmale lernt, die für die Objekterkennung ausschlaggebend sind.

Als Indikator für den Fortschritt in der Entwicklung von CNNs können die Metriken Top-1 bzw. Top-5 Accuracy vom Wettbewerb \emph{ImageNet Large Scale Visual Recognition Challenge} (ILSVRC) \cite{russakovsky2015imagenet} herangezogen werden. In ILSVRC werden Modelle mit der Bildklassifizierung des \emph{ImageNet-Datensatzes} beauftragt, der tausend nicht überlappende Klassen und ca. 1,35 Millionen Bilder umfasst\footnote{Tatsächlich ist der zu klassifizierende Datensatz nur eine Teilmenge des realen ImageNet-Datensatzes, der gemäß \cite{ridnik2021imagenet21k} 21\,841 überlappende Klassen umfasst. Zum Unterscheiden wird im Weiteren die Teilmenge als ImageNet(-1K), der reale Datensatz als ImageNet-21K bezeichnet.}. Die Top-K Accuracy stellt den Anteil der Validierungs- oder Testbilder dar, für die die Top-K-Prognosen des zu testenden Modells die richtige Antwort enthalten. Nach \emph{Papers with Code} \cite{PapersWithCode-ImageNet} sind die folgenden Modelle zum Zeitpunkt dieser Arbeit Stand der Technik im Bereich der Bildklassifizierung:

\begin{enumerate}
	\item \emph{Vision-Transformer} \cite{dosovitskiy2021image} - Beste ImageNet Top-1 Accuracy: 90,45\%  \cite{zhai2021scaling}
	\item \emph{EfficientNet} \cite{tan2020efficientnet} - Beste ImageNet Top-1 Accuracy: 90,20\%  \cite{pham2021meta}
	\item \emph{ResNet} \cite{he2015deep} - Beste ImageNet Top-1 Accuracy: 87,54\% \cite{kolesnikov2020big}
\end{enumerate}

\subsection{Transfer Learning}

Zur visuellen Erkennung von Tierarten im Projekt Natur 4.0 werden keine Modelle von Grund auf trainiert, sondern \emph{vortrainierte Modelle} eingesetzt (z.~B. die oben aufgeführten Modelle, die bereits auf dem ImageNet-Datensatz trainiert wurden). Auf diese Modelle wird das Konzept des \emph{Transfer Learnings} angewendet. Transfer Learning ist eine Methode, in der ein für eine Aufgabe entwickeltes Modell als Ausgangspunkt für eine andere ähnliche Aufgabe wiederverwendet wird. Ein vortrainiertes Modell sollte aufgrund seines großen Trainingsdatensatzes bereits Low-Level-Merkmale gelernt haben, die zur visuellen Erkennung von Tierarten relevant oder nützlich sein können. Man kann somit Teile des aufwendigen Trainings überspringen und infolgedessen Zeit sowie Speicher- und Rechenressourcen sparen, denn komplexe CNN-Modelle können in der Praxis tage- oder wochenlang von Grund auf trainiert werden \cite[4]{Schroff_2015}\cite[1]{codreanu2017scale}\cite{BBVADeepLearning,StanfordDAWNBench}.

%Da die aufgeführten Modelle zuvor auf dem ImageNet-Datensatz trainiert wurden, der zahlreiche Tierarten unter seinen tausend Klassen enthält\footfullcite{ImageNet1000Classes}, ist es durchaus möglich, dass diesen Modellen Grundunterschiede zwischen Tierarten schon bekannt sind, d.~h. die Modelle haben mit hoher Wahrscheinlichkeit ihre Gewichte zum Trennen von Tierarten optimiert. 

%Die Verwendung dieser Gewichte anstatt zufällig initialisierter Gewichte kann zur besseren Vorinitialisierung der Modelle dienen, die zur visuellen Erkennung von Tierarten eingesetzt werden. 

\section{Die zentralen Fragestellungen}

Die visuelle Erkennung von Tierarten im Projekt Natur 4.0 ist ein Objekterkennungsproblem, das sich mit einem datengetriebenen Ansatz lösen lässt. Damit dieser Lösungsansatz nach dem Transfer-Learning-Konzept umgesetzt werden kann, sind folgende Fragestellungen zu beantworten:

\begin{enumerate}
	\item \textbf{Welche vortrainierten CNN-Modelle werden zur visuellen Erkennung von Tierarten im Projekt Natur 4.0 eingesetzt?}
	
	\item \textbf{Wie werden die ausgewählten CNN-Modelle dazu angepasst?}
	
	\item \textbf{Welche Leistung können die ausgewählten CNN-Modelle nach dem Tuning erzielen?}
\end{enumerate}

Antworten auf die aufgeführten Fragestellungen lassen sich der Reihe nach in \autoref{chap:relatedwork}, \autoref{chap:training} sowie \autoref{chap:experimentresult} finden. Um jedoch die Argumentationen nachzuvollziehen, die zu diesen Antworten geführt haben, wird empfohlen, zunächst die grundlegenden Konzepte von CNNs zu verstehen, die in \autoref{chap:grundlagen} ausführlicher beschrieben sind.