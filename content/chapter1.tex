\chapter{Einleitung}

Im Zentrum des ersten Kapitels steht der Einsatz von \emph{Deep Learning} im Bereich der Umweltbeobachtung. Es werden auch Fragestellungen aufgeführt, die einen Überblick über den Aufbau der Arbeit geben.

\section{Deep Learning in der Umweltbeobachtung}

Der \emph{LOEWE-Schwerpunkt Natur 4.0 Sensing Biodiversity} (abgekürzt: Natur 4.0) ist ein Gemeinschaftsprojekt der federführenden Philipps-Universität Marburg, der Justus-Liebig-Universität Gießen, der Technische Universität Darmstadt und der Senckenberg Gesellschaft für Naturforschung in Frankfurt. Ziel des Projekts ist \textquote[{\footfullcite{LOEWE-Natur4.0}}]{die Entwicklung eines Umweltmonitoringsystems zur hoch aufgelösten Beobachtung von naturschutzrelevanten Arten, Lebensräumen und Prozessen} durch vernetzte Sensorik und integrative Datenanalyse. Das Testgebiet für die Prototypentwicklung von Natur 4.0 ist der Marburger Universitätswald in Caldern. 

Einer der Schwerpunkte des Projekts liegt auf \textbf{der visuellen Erkennung von Tierarten}. Die Ergebnisse dieser Aufgabe ermöglichen zusammen mit weiteren zeitlichen und räumlichen Sensordaten die Beantwortung folgender Fragen: Welche Tierarten sind im Testgebiet vorhanden? Wann, wie häufig, wo genau und unter welchen Bedingungen kommen sie vor? Die Antworten auf diese Fragestellungen erweisen sich als wertvoll: Sie geben nicht nur Auskunft über die biologische Vielfalt und Eigenschaften von Ökosystemen im Testgebiet, sondern auch über die Wechselwirkungen zwischen Tieren, Pflanzen und klimatischen Bedingungen darin. Aus solchen Informationen lassen sich verschiedene Naturschutzstrategien ableiten.

Bei einem gegebenen Bild gilt die visuelle Erkennung von Tierarten als erfolgreich, wenn alle Tiere in diesem Bild gefunden und richtig kategorisiert werden. Die Aufgabe ist in der Tat ein typisches Beispiel für \emph{das Objekterkennungsproblem}.

\subsection{Objekterkennung}

Die Objekterkennung im Forschungsfeld \emph{Computer Vision} erfolgt in zwei Schritten:

\begin{enumerate}
	\item \emph{Objektlokalisierung}: Der erste Schritt bezieht sich auf das Identifizieren der Position eines oder mehrerer Objekte in einem Bild und das Zeichnen eines Begrenzungsrahmens um ihre Ausdehnung.
	
	\item \emph{Bildklassifizierung}: Bei dem zweiten Schritt handelt es sich um die Aufgabe, einem Bildobjekt ein Label aus einem festen Satz von Kategorien zuzuweisen.
\end{enumerate}

Auf die gleiche Weise lässt sich die visuelle Erkennung von Tierarten erledigen. Die Tiere im Eingabebild müssen zunächst lokalisiert und anschließend klassifiziert werden, um als richtig erkannt zu gelten.

Man verwendet \emph{den datengetriebenen Ansatz}, um das Objekterkennungsproblem zu lösen. Die Idee dabei ist, dem Computer viele Fotos jeder einzelnen Objektklasse bereitzustellen und dann mit dem Computer Lernalgorithmen zu entwickeln, die sich diese Fotos ansehen und visuelle Merkmale lernen, die Objekte von ihrer Umgebung und jede Klasse voneinander trennen. Ergebnis der Lernphase ist ein \emph{trainiertes Modell}, das aus Fotodaten im Rahmen des Projekts Natur 4.0 bestimmte Tierarten erkennen können soll.

Die zu entwickelnden Algorithmen im datengetriebenen Ansatz fallen unter die Kategorie \emph{Deep-Learning-Algorithmen}, die die Lernfähigkeit von Computern ermöglichen.

\subsection{Deep Neural Network}

In der Regel besteht ein Deep-Learning-Algorithmus (im Weiteren als \emph{Deep Neural Network} (DNN) bezeichnet) aus einer \emph{Eingabeschicht}, einer \emph{Ausgabeschicht} und zahlreichen \emph{verborgenen Schichten}. Jede Schicht setzt sich aus \emph{Neuronen} zusammen, die Informationen von anderen Neuronen oder von außen aufnehmen, modifizieren und als Ergebnis ausgeben (siehe \autoref{fig:DNN}).

\begin{figure}[!hb]
	\centering
	\includegraphics[width=\linewidth]{images/DNN}
	\caption{Aufbau eines Deep Neural Network}
	\label{fig:DNN}
\end{figure}

Für die Objekterkennung verwendet man einen bestimmten Typ von DNN namens \emph{Convolutional Neural Network} (CNN) (mehr dazu im \autoref{sec:cnn}). Unterschiedliche CNNs haben unterschiedliche Anordnungen von Schichten unterschiedlicher Typen (Architekturen), jedoch die gleiche Funktionsweise: CNNs konzentrieren sich auf \emph{Low-Level-Merkmale} in den ersten Schichten und setzen diese anschließend in den nächsten zu \emph{Higher-Level-Merkmale} zusammen. Beispielweise kann der Computer in niedrigeren Schichten lernen, Kanten oder Linien oder auch Kurven aus Pixel der Eingabebilder zu identifizieren, während er in höheren Schichten komplexere Formen sowie visuelle Merkmale lernt, die für die Objekterkennung ausschlaggebend sind.

Als Indikator für den Fortschritt bei der Entwicklung von CNNs im Bereich Computer Vision können die Metriken Top-1- bzw. Top-5-Genauigkeit vom Wettbewerb \emph{ImageNet Large Scale Visual Recognition Challenge (ILSVRC)}\cite{russakovsky2015imagenet} herangezogen werden. In ILSVRC werden CNNs mit der Bildklassifizierung des \emph{ImageNet-Datensatzes} beauftragt, der tausend nicht überlappende Klassen und ca. 1,35 Millionen Bilder umfasst. Die Top-K-Genauigkeit stellt den Anteil der Testbilder dar, für die die Top-K-Prognosen des zu testenden CNN die richtige Antwort enthalten. Laut \emph{Papers with Code}\footfullcite{PapersWithCode-ImageNet} sind die folgenden CNN-Architekturen mit ihrer jeweiligen ILSVRC Top-1-Genauigkeit zum Zeitpunkt dieser Arbeit Stand der Technik:

\begin{enumerate}
	\item \emph{Transformer}\cite{dosovitskiy2021image} - 87,76\%
	\item \emph{EfficientNet}\cite{tan2020efficientnet} - 84,40\%
	\item \emph{ResNet}\cite{he2015deep} - 78,57\%.
\end{enumerate}

Zur visuellen Erkennung von Tierarten im Projekt Natur 4.0 wird eines der aufgeführten CNN-Modelle (trainierten CNN-Architekturen) eingesetzt. Der Grund dafür basiert auf dem Konzept von \emph{Transfer Learning}, das im Grunde eine Methode ist, die ein für eine Aufgabe A entwickeltes Modell als Ausgangspunkt für eine andere ähnliche B wiederverwendet. Ein solches Modell könnte bereits Merkmale gelernt haben, die für Aufgabe B relevant oder nützlich sind. Da die aufgeführten CNN-Modelle zuvor auf dem ImageNet-Datensatz trainiert wurden, der mehrere Tierarten unter seinen tausend Klassen enthält\footfullcite{ImageNet1000Classes}, ist es durchaus möglich, dass diesen Modellen Grundunterschiede zwischen den zu trennenden Tierarten bekannt sind. Deshalb kann man Teile des aufwendigen Trainings überspringen und infolgedessen Zeit sowie Speicher- und Rechenressourcen sparen, denn komplexe CNNs können in der Praxis tage- oder wochenlang von Grund auf trainiert werden\cite[4]{Schroff_2015}\cite[1]{codreanu2017scale}\cite{StanfordDAWNBench,BBVADeepLearning}. 

\section{Die zentralen Fragestellungen}

Die visuelle Erkennung von Tierarten im Projekt Natur 4.0 ist ein Objekterkennungsproblem, das sich mit dem datengetriebenen Ansatz lösen lässt. Damit dieser Lösungsansatz umgesetzt werden kann, sind folgende Fragestellungen zu beantworten:

\begin{enumerate}
	\item \textbf{Welches vortrainierte CNN-Modell wird zur visuellen Erkennung von Tierarten im Projekt Natur 4.0 eingesetzt?}
	
	\item \textbf{Wie wird das ausgewählte CNN-Modell nachtrainiert?}
	
	\item \textbf{Welche Leistung kann das nachtrainierte CNN-Modell erzielen?}
\end{enumerate}

Antworten auf die aufgelisteten Fragestellungen lassen sich der Reihe nach im \autoref{chap:relatedwork}, im \autoref{chap:training} bzw. im \autoref{chap:experimentresult} finden. Um jedoch die Argumentationen nachzuvollziehen, die zu diesen Antworten geführt haben, wird empfohlen, zunächst die grundlegenden Konzepte von CNN zu verstehen, die im \autoref{chap:grundlagen} ausführlicher beschrieben sind.